{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\\\\\\\ad.monash.edu\\\\home\\\\user007\\\\prcle2\\\\documents\\\\demarco\\\\autoliftout\\\\liftout\\\\model\\\\models\\\\boost_n05_model.pt', '\\\\\\\\ad.monash.edu\\\\home\\\\user007\\\\prcle2\\\\documents\\\\demarco\\\\autoliftout\\\\liftout\\\\model\\\\models\\\\fresh_full_n10.pt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from liftout.model.utils import *\n",
    "from liftout import model\n",
    "from fibsem.detection.detection import *\n",
    "from fibsem.detection.DetectionModel import *\n",
    "from fibsem.detection.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "# print(os.path.dirname(model.__file__))\n",
    "\n",
    "model_path = os.path.dirname(model.__file__)\n",
    "model_filenames = glob.glob(\n",
    "    os.path.join(model_path, \"models\", \"*.pt\")\n",
    ")\n",
    "\n",
    "\n",
    "image_fnames = glob.glob(\n",
    "    os.path.join(model_path, \"data/data/train/raw/000001*.tif\")\n",
    ")\n",
    "\n",
    "shuffle(image_fnames)\n",
    "model_filenames = sorted([fname for fname in model_filenames if any(match in fname for match in [\"boost_n05\", \"fresh\"])]) #\"n10\", \"baseline\"\n",
    "# any(x in a_string for x in matches)(\"boost\" in fname) or (\"n10\" in fname)])\n",
    "\n",
    "# there is a smarter way to do this (just order them correctly)\n",
    "# model_filenames.insert(1, model_filenames[-2])\n",
    "# model_filenames.insert(2, model_filenames[-1])\n",
    "# model_filenames.pop()\n",
    "# model_filenames.pop()\n",
    "# model_filenames.pop()\n",
    "print(model_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: fresh_full_n10.pt\n",
      "saving: boost_n05_model.pt\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a grid of images with each row showing a different model\n",
    "\n",
    "N_IMAGES = 10\n",
    "EXP_NAME = input(\"Enter a name for the experiment\")\n",
    "EXP_PATH = os.path.join(\"eval\", EXP_NAME)\n",
    "os.makedirs(\n",
    "    EXP_PATH, exist_ok=True)\n",
    "    \n",
    "image_fnames = image_fnames[:N_IMAGES]\n",
    "\n",
    "exp_array = None\n",
    "for weights_file in reversed(model_filenames):\n",
    "    # load detector\n",
    "    detector = Detector(weights_file=weights_file)\n",
    "    detector.detection_model.model.eval()\n",
    "\n",
    "    img_array = None\n",
    "\n",
    "    for fname in image_fnames:\n",
    "        # load image from file\n",
    "        img = load_image_from_file(fname)\n",
    "    \n",
    "        # model inference\n",
    "        mask = detector.detection_model.inference(img)\n",
    "\n",
    "        # individual detection modes\n",
    "        lamella_mask, lamella_idx = extract_class_pixels(mask, color=(255, 0, 0)) # red\n",
    "        needle_mask, needle_idx = extract_class_pixels(mask, color=(0, 255, 0)) # green\n",
    "\n",
    "        feature_1_px, lamella_centre_detection = detect_lamella_centre(img, mask) # lamella_centre\n",
    "        feature_2_px, needle_tip_detection = detect_needle_tip(img, mask)\n",
    "        feature_3_px, lamella_edge_detection = detect_lamella_edge(img, mask)\n",
    "\n",
    "        mask_combined = draw_two_features(mask, feature_1_px, feature_2_px)\n",
    "        img_blend = draw_overlay(img, mask_combined)\n",
    "        \n",
    "        if img_array is None:\n",
    "            img_array = np.array(img_blend)\n",
    "\n",
    "        else:\n",
    "            img_array = np.hstack((img_array, np.array(img_blend)))\n",
    "\n",
    "    print(f\"saving: {os.path.basename(weights_file)}\")\n",
    "    img_pil = Image.fromarray(img_array)\n",
    "    img_pil.save(os.path.join(EXP_PATH, f\"{os.path.basename(weights_file)}.png\"))\n",
    "\n",
    "    if exp_array is None:\n",
    "        exp_array = img_array\n",
    "    else:\n",
    "        exp_array = np.vstack((exp_array, img_array))\n",
    "\n",
    "exp_img_pil = Image.fromarray(exp_array)\n",
    "exp_img_pil.save(os.path.join(EXP_PATH,f\"experiment.png\"))\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a grid of images from a list of image filenames\n",
    "image_fnames = glob.glob(\n",
    "    os.path.join(model_path, \"images/test/**/*.tif\")\n",
    ")\n",
    "\n",
    "shuffle(image_fnames)\n",
    "\n",
    "imgs = [load_image_from_file(fname) for fname in image_fnames]\n",
    "detector = Detector(weights_file=\"models/boost_n05_model.pt\")\n",
    "detector.detection_model.model.eval()\n",
    "\n",
    "MAX_COLS = 10\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "full_img = None\n",
    "row = None\n",
    "while image_fnames:\n",
    "    \n",
    "    img = load_image_from_file(image_fnames.pop())\n",
    "    \n",
    "    # model inference\n",
    "    mask = detector.detection_model.inference(img)\n",
    "    feature_1_px, lamella_centre_detection = detect_lamella_centre(img, mask) # lamella_centre\n",
    "    feature_2_px, needle_tip_detection = detect_needle_tip(img, mask)\n",
    "\n",
    "    mask_combined = draw_two_features(mask, feature_1_px, feature_2_px)\n",
    "    img_blend = draw_overlay(img, mask_combined)\n",
    "\n",
    "    j += 1\n",
    "    \n",
    "    if row is None:\n",
    "        row = img_blend\n",
    "    else:\n",
    "        row = np.hstack((row, img_blend))\n",
    "\n",
    "    if j >= MAX_COLS:\n",
    "        \n",
    "        if full_img is None:\n",
    "            full_img = row\n",
    "        else:\n",
    "            full_img = np.vstack((full_img, row))\n",
    "        i += 1\n",
    "        j = 0\n",
    "        row = None\n",
    "\n",
    "img_pil = Image.fromarray(full_img).convert(\"RGB\")\n",
    "img_pil.save(\"grid.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from liftout.model.utils import *\n",
    "from liftout import model\n",
    "from fibsem.detection.detection import *\n",
    "from fibsem.detection.DetectionModel import *\n",
    "from fibsem.detection.utils import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "# print(os.path.dirname(model.__file__))\n",
    "\n",
    "model_path = os.path.dirname(model.__file__)\n",
    "model_filenames = glob.glob(\n",
    "    os.path.join(model_path, \"models\", \"boost*.pt\")\n",
    ")\n",
    "\n",
    "\n",
    "# print(model_filenames)\n",
    "detector = Detector(weights_file=model_filenames[0])\n",
    "detector.detection_model.model.cuda()\n",
    "# detector.detection_model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001CE30C43BA0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detection_model.model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.335483999999994 MB\n"
     ]
    }
   ],
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in detector.detection_model.model.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in detector.detection_model.model.buffers()])\n",
    "mem = mem_params + mem_bufs # in bytes\n",
    "print(mem * 1e-6, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9b33737b1f758ada5d3d8c5f057adce70040e01798d7d541457e265d7d82dbbb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
